{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Primero cargamos el dataset de iris y creamos unva lista con los nombres de las diferentes clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np                                         \n",
    "from sklearn.neural_network import MLPClassifier           \n",
    "from sklearn.model_selection import train_test_split     \n",
    "\n",
    "classes = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "\n",
    "iris = np.loadtxt('../practices/data/iris.csv', delimiter=',')\n",
    "iris[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Ahora Formamos la matriz X que contiene la informacion de las 4 caracteristicas y el vector Y que contiene cada una de sus clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris[:, :-1]\n",
    "Y = iris[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Dividimos nuestros datos en training y test. Tomamos el 15% para test y el resto para test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Entrenamos a nuestro modelo haciendo uso de una red neuronal que es un perceptron multicapa. Para este procedimiento utilizamos los datos de training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=20, max_iter=300, random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier(solver='lbfgs', hidden_layer_sizes=20, random_state=1, max_iter=300)\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Con nuestro modelo listo procedemos a crear una matriz con los nuevos datos de la pr√°ctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [6.2, 3.1, 5.3, 1.9],\n",
       "       [5.1, 3.1, 1.3, 0.2],\n",
       "       [6.8, 3.3, 4.1, 1.1],\n",
       "       [5.9, 2.9, 4.6, 1.3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_flowers = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],\n",
    "    [6.2, 3.1, 5.3, 1.9],\n",
    "    [5.1, 3.1, 1.3, 0.2],\n",
    "    [6.8, 3.3, 4.1, 1.1],\n",
    "    [5.9, 2.9, 4.6, 1.3]\n",
    "])\n",
    "new_flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Ahora procedemos a predecir la clase a la que pertenece cada flor en base a sus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.uint8(model.predict(new_flowers))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Como podemos observar nos devuelve el numero de clase a la que pertenece cada flor, ahora lo que hacemos es usar ese numero para mostrar su respectiva etiqueta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris-setosa',\n",
       " 'Iris-virginica',\n",
       " 'Iris-setosa',\n",
       " 'Iris-versicolor',\n",
       " 'Iris-versicolor']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_labels = [classes[i] for i in predictions]\n",
    "pred_labels"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Wilson Aguilar"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
